"""Re-rankingå‰å¾Œã®æ¤œç´¢çµæœã‚’æ¯”è¼ƒã™ã‚‹ç°¡æ˜“è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨æ–¹æ³•:
    python eval/compare_reranking.py

ç’°å¢ƒå¤‰æ•°:
    OPENAI_API_KEY: OpenAI APIã‚­ãƒ¼ï¼ˆå¿…é ˆï¼‰
    COHERE_API_KEY: Cohere APIã‚­ãƒ¼ï¼ˆRe-rankingæœ‰åŠ¹æ™‚ã®ã¿å¿…é ˆï¼‰
"""

import json
import sys
import os
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from initialize import initialize_system
from retriever import search_with_scores, rerank_search_results
from constants import (
    DEFAULT_DATA_FOLDER, DEFAULT_K, DEFAULT_BM25_WEIGHT,
    DEFAULT_VECTOR_WEIGHT, RERANK_TOP_K_BEFORE
)

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()


def run_comparison():
    """Re-rankingå‰å¾Œã®æ¤œç´¢çµæœã‚’æ¯”è¼ƒ"""

    print("=" * 80)
    print("Re-ranking å‰å¾Œæ¯”è¼ƒè©•ä¾¡")
    print("=" * 80)

    # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
    eval_file = Path(__file__).parent / "eval_dataset.json"
    with open(eval_file, 'r', encoding='utf-8') as f:
        test_cases = json.load(f)

    # Re-rankingåŠ¹æœæ¸¬å®šç”¨ã®ã‚±ãƒ¼ã‚¹ã‚’æŠ½å‡º
    rerank_cases = [tc for tc in test_cases if tc.get('category') == 'Re-rankingåŠ¹æœæ¸¬å®š']
    if not rerank_cases:
        print("âš ï¸ Re-rankingåŠ¹æœæ¸¬å®šç”¨ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã§è©•ä¾¡ã—ã¾ã™...")
        rerank_cases = test_cases[:5]  # æœ€åˆã®5ä»¶

    print(f"\nãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(rerank_cases)}")

    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    print("\nåˆæœŸåŒ–ä¸­...")
    try:
        init_result = initialize_system(
            data_folder=DEFAULT_DATA_FOLDER,
            bm25_weight=DEFAULT_BM25_WEIGHT,
            vector_weight=DEFAULT_VECTOR_WEIGHT,
            k=DEFAULT_K
        )

        if init_result['index_count'] == 0:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {DEFAULT_DATA_FOLDER} ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
            return

        print(f"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†: {init_result['index_count']} ãƒãƒ£ãƒ³ã‚¯")

        hybrid_retriever = init_result['hybrid_retriever']

    except Exception as e:
        print(f"âŒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
        return

    # æ¯”è¼ƒçµæœã‚’æ ¼ç´
    results = []

    for idx, test_case in enumerate(rerank_cases, 1):
        query = test_case['question']
        print(f"\n[{idx}/{len(rerank_cases)}] {query}")
        print("-" * 80)

        # Re-rankingç„¡åŠ¹ã§æ¤œç´¢
        print("\nã€Re-rankingç„¡åŠ¹ã€‘")
        try:
            results_without_rerank = search_with_scores(
                ensemble_retriever=hybrid_retriever,
                query=query,
                k=DEFAULT_K
            )

            print(f"æ¤œç´¢çµæœ: {len(results_without_rerank)}ä»¶")
            for i, result in enumerate(results_without_rerank[:3], 1):
                print(f"  {i}. ã‚¹ã‚³ã‚¢: {result['score']:.3f} | {result['heading'][:50]}")

        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            results_without_rerank = []

        # Re-rankingæœ‰åŠ¹ã§æ¤œç´¢ï¼ˆLLMãƒ™ãƒ¼ã‚¹ï¼‰
        print("\nã€Re-rankingæœ‰åŠ¹ï¼ˆLLMï¼‰ã€‘")
        try:
            # ã‚ˆã‚Šå¤šãã®çµæœã‚’å–å¾—
            results_before_rerank = search_with_scores(
                ensemble_retriever=hybrid_retriever,
                query=query,
                k=RERANK_TOP_K_BEFORE
            )

            # Re-rankingé©ç”¨ï¼ˆLLMãƒ™ãƒ¼ã‚¹ - OpenAI APIã‚’ä½¿ç”¨ï¼‰
            results_with_rerank = rerank_search_results(
                query=query,
                search_results=results_before_rerank,
                k=DEFAULT_K,
                method="llm"
            )

            print(f"æ¤œç´¢çµæœ: {len(results_with_rerank)}ä»¶")
            for i, result in enumerate(results_with_rerank[:3], 1):
                rerank_score = result.get('rerank_score', 0.0)
                print(f"  {i}. Re-rankã‚¹ã‚³ã‚¢: {rerank_score:.3f} | å…ƒã‚¹ã‚³ã‚¢: {result['score']:.3f} | {result['heading'][:50]}")

        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            if "COHERE_API_KEY" in str(e):
                print("  ğŸ’¡ ãƒ’ãƒ³ãƒˆ: .envãƒ•ã‚¡ã‚¤ãƒ«ã«COHERE_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
            results_with_rerank = []

        # çµæœã‚’è¨˜éŒ²
        results.append({
            'question': query,
            'without_rerank': [
                {
                    'heading': r['heading'],
                    'score': r['score'],
                    'file': r['file']
                }
                for r in results_without_rerank[:3]
            ],
            'with_rerank': [
                {
                    'heading': r['heading'],
                    'score': r['score'],
                    'rerank_score': r.get('rerank_score', 0.0),
                    'file': r['file']
                }
                for r in results_with_rerank[:3]
            ]
        })

    # çµæœã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_file = Path(__file__).parent / f"rerank_comparison_{Path(DEFAULT_DATA_FOLDER).name}.json"
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 80)
    print(f"âœ… æ¯”è¼ƒçµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_file}")
    print("=" * 80)

    # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
    print("\nã€ã‚µãƒãƒªãƒ¼ã€‘")
    print(f"- ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°: {len(rerank_cases)}")
    print(f"- Re-rankingç„¡åŠ¹ã®å¹³å‡ã‚¹ã‚³ã‚¢: {_calc_avg_score([r['without_rerank'] for r in results]):.3f}")
    print(f"- Re-rankingæœ‰åŠ¹ã®å¹³å‡Re-rankã‚¹ã‚³ã‚¢: {_calc_avg_rerank_score([r['with_rerank'] for r in results]):.3f}")
    print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ã€Re-rankingåŠ¹æœã‚’åˆ†æ")
    print("  2. ã‚ˆã‚Šè©³ç´°ãªè©•ä¾¡ã‚’è¡Œã†å ´åˆã¯ã€LLM as a Judgeè©•ä¾¡ã‚’å®Ÿè¡Œ")


def _calc_avg_score(results_list):
    """å¹³å‡ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    scores = []
    for results in results_list:
        for result in results:
            scores.append(result.get('score', 0.0))
    return sum(scores) / len(scores) if scores else 0.0


def _calc_avg_rerank_score(results_list):
    """å¹³å‡Re-rankã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    scores = []
    for results in results_list:
        for result in results:
            scores.append(result.get('rerank_score', 0.0))
    return sum(scores) / len(scores) if scores else 0.0


if __name__ == "__main__":
    run_comparison()
